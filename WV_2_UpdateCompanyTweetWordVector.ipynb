{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import pymongo\n",
    "#from pymongo import MongoClient \n",
    "from nltk.tokenize import TweetTokenizer \n",
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "import collections\n",
    "import operator\n",
    "from nltk.util import ngrams\n",
    "import datetime \n",
    "import numpy as np\n",
    "from nltk.corpus import sentiwordnet as swn \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import pymongo\n",
    "#from pymongo import MongoClient \n",
    "from nltk.tokenize import TweetTokenizer \n",
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "import collections\n",
    "import operator\n",
    "from nltk.util import ngrams\n",
    "import json\n",
    "\n",
    "client = pymongo.MongoClient('mongodb://TwitterIPO?authSource=TwitterIPO')\n",
    "\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "def clean_tweet(t):\n",
    "\n",
    "    t = t.replace('RT ','')\n",
    "    t = t.replace('$','')\n",
    "    t = t.replace('#','')\n",
    "    \n",
    "    for word in t:\n",
    "        if word.startswith((\"@\")) == True:\n",
    "            t = t.replace(word,'')\n",
    "            \n",
    "    t = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''','',t)\n",
    "\n",
    "    t = t.replace(',','')\n",
    "    t = t.replace('.','')\n",
    "    t = t.replace(';','')\n",
    "    t = t.replace(\"'\",'')\n",
    "    t = t.replace('\"','')\n",
    "    t = t.replace('...','')\n",
    "    t = t.replace('…','')\n",
    "    t = t.replace('’','')\n",
    "    t = t.replace('/','')\n",
    "    t = t.replace('/','')\n",
    "    t = t.replace('-->','')\n",
    "    t = t.replace('(','')\n",
    "    t = t.replace('[','')\n",
    "    t = t.replace(']','')\n",
    "    t = t.replace(')','')\n",
    "    t = t.replace(':','')\n",
    "    t = t.replace('-','')\n",
    "    t = t.replace('!','')\n",
    "    t = t.replace('|','')\n",
    "    t = t.replace('?','')\n",
    "    t = t.replace('>','')\n",
    "    t = t.replace('*','')\n",
    "    return(t.lower())\n",
    "\n",
    "allowed_word_types = [\"J\",\"R\",\"V\"]\n",
    "\n",
    "cursor=client.TwitterIPO.ProcessedTweets.find({ \"lang\": \"en\" } )\n",
    "tweetDataFrame =  pd.DataFrame(list(cursor))\n",
    "tweetDataFrame\n",
    "\n",
    "wordcountdic={}\n",
    "tweetmessages=pd.unique(tweetDataFrame[['tweet_id', 'text','company']].values)\n",
    "\n",
    "positiveWord= client.TwitterIPO.PositiveWords.find({},{\"Word\":1}).sort([(\"Word\",pymongo.ASCENDING)])\n",
    "negativeWord= client.TwitterIPO.NegativeWords.find({},{\"Word\":1}).sort([(\"Word\",pymongo.ASCENDING)])\n",
    "positiveWordDF =  pd.DataFrame(list(positiveWord))\n",
    "negativeWordDF =  pd.DataFrame(list(negativeWord))\n",
    "\n",
    "tknz = TweetTokenizer()\n",
    "tokenizetweet=()\n",
    "\n",
    "wordfrequencycursor=client.TwitterIPO.WordFrequencies.find({ },{\"Word\":1})\n",
    "wordfrequencydf =  pd.DataFrame(list(wordfrequencycursor))\n",
    "newcolumn=wordfrequencydf['Word'].tolist()\n",
    "\n",
    "wordOccurences=dict.fromkeys(newcolumn,0)\n",
    "\n",
    "tweetDataFrame['date_minus_time'] = tweetDataFrame[\"datepy\"].apply( lambda dt : datetime.datetime(year=dt.year, month=dt.month, day=dt.day)) \n",
    "result = tweetDataFrame[['company','date_minus_time']].groupby(['company','date_minus_time']).count()\n",
    "datedf=result.reset_index()\n",
    "companyList=tweetDataFrame.groupby(['company']).count().reset_index()\n",
    "\n",
    "\n",
    "for row in companyList.iterrows():\n",
    "    \n",
    "    company = row[1][0]\n",
    "    print(\"start company \",company)\n",
    "    cursor3=client.TwitterIPO.ProcessedTweets.find({ \"company\": company} )\n",
    "    companytweetDataFrame =  pd.DataFrame(list(cursor3))\n",
    "    companytweetDataFrame['date_minus_time'] = companytweetDataFrame[\"datepy\"].apply( lambda dt : datetime.datetime(year=dt.year, month=dt.month, day=dt.day)) \n",
    "   \n",
    "    listofdate= companytweetDataFrame[['date_minus_time']].groupby(['date_minus_time']).count().reset_index() #datedf[datedf.company==company]\n",
    "\n",
    "    for date in listofdate.iterrows():\n",
    "        currentdate=date[1][0]\n",
    "        #print(type(currentdate))\n",
    "        #print(\"start date \")\n",
    "        alltweetoncurrentdate=companytweetDataFrame[(companytweetDataFrame.date_minus_time== currentdate)]\n",
    "        for textinthatday in alltweetoncurrentdate.iterrows():\n",
    "            text=textinthatday[1][6]\n",
    "            date=textinthatday[1][4]\n",
    "            cleantweet= clean_tweet(text)\n",
    "            listoftoken= tknz.tokenize(cleantweet)\n",
    "            for currenttoken in listoftoken:\n",
    "                if currenttoken in newcolumn:\n",
    "                    numberoftokent=list(client.TwitterIPO.CompanyTweetWordVector.find({ \"ipo_company\": company,\"price_date\":currentdate},{currenttoken:1}))\n",
    "  \n",
    "                    originalvalue=numberoftokent[0][currenttoken]\n",
    "                    if((positiveWordDF['Word']==currenttoken).any()):\n",
    "                        newvalue= originalvalue+1\n",
    "                        #print(newvalue)\n",
    "                        client.TwitterIPO.CompanyTweetWordVector.update_one({\"ipo_company\": company,\"price_date\": currentdate} , {\"$set\": {currenttoken: newvalue}})\n",
    "                    if((negativeWordDF['Word']==currenttoken).any()):\n",
    "                        newvalue= originalvalue-1\n",
    "                        #print(newvalue)\n",
    "                        client.TwitterIPO.CompanyTweetWordVector.update_one({ \"ipo_company\": company,\"price_date\":currentdate} , {\"$set\": {currenttoken: newvalue}})\n",
    "                        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
